{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0677302b",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "In this project, I used logistic regression to classify handwritten digits using the dataset available in scikit-learn, known as the load_digits dataset. The dataset contains images of handwritten digits (0-9), making it a suitable benchmark for image classification tasks. By applying logistic regression, a foundational classification algorithm, I aimed to accurately predict the digit represented in each image based on its pixel values.\n",
    "\n",
    "### Objective:\n",
    "The primary objective of this project is to develop a logistic regression model capable of accurately classifying handwritten digits from the load_digits dataset. Through this project, I seek to demonstrate proficiency in image classification tasks and highlight the effectiveness of logistic regression in real-world scenarios.\n",
    "\n",
    "### Methodologies:\n",
    "\n",
    "##### 1. Data Acquisition: \n",
    "I utilized the load_digits() function from the sklearn.datasets module to load the load_digits dataset, which contains images of handwritten digits along with their corresponding labels.\n",
    "\n",
    "##### 2. Exploratory Data Analysis: \n",
    "Before model development, I explored the dataset to understand its structure and characteristics. Visualization techniques were employed to gain insights into the distribution of digits and the appearance of handwritten images.\n",
    "\n",
    "##### 3. Data Preprocessing: \n",
    "The dataset was split into training and testing sets for model training and evaluation.\n",
    "\n",
    "##### 4. Model Development: \n",
    "A logistic regression model was constructed using the LogisticRegression class from sklearn.linear_model. The model was trained on the training data using the fit() method.\n",
    "\n",
    "##### 5. Model Evaluation: \n",
    "Following model training, predictions were made on the testing data using the predict() method. Performance metrics such as accuracy score and classification report were computed to assess the model's effectiveness in digit classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92ef683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "156925fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44315d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the dataset\n",
    "dir(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc91a023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can view first five rows\n",
    "digits.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41a22603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data array: (1797, 64)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the data\n",
    "print(\"Shape of data array:\", digits.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd7a45",
   "metadata": {},
   "source": [
    "digits.data contains the flattened images, where each row represents an image and each column represents a pixel. So, digits.data.shape returns the number of samples (images) and the number of features (pixels) per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a18cb37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features per sample: 64\n"
     ]
    }
   ],
   "source": [
    "# Check the number of features\n",
    "print(\"Number of features per sample:\", digits.data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09fddaa",
   "metadata": {},
   "source": [
    "Since each image in the digits dataset is an 8x8 pixel image (flattened into a 1D array of length 64), the code gives the number of pixels in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ee1f373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of target array: (1797,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the target array\n",
    "print(\"Shape of target array:\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e6d844",
   "metadata": {},
   "source": [
    " This code shows the shape of the target array (digits.target), which contains the labels corresponding to each image in the dataset.It should match the number of samples in the feature matrix (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b65c7301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let us visualize the first 5 images\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(digits.images[i])\n",
    "    plt.title(f\"Digit: {digits.target[i]}\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cee8f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us see the first five target variables\n",
    "digits.target[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41439209",
   "metadata": {},
   "source": [
    "We can see that the first five images correspond to the first five targets, which are 0 to 5.\n",
    "So, remember, we have a dataset with different numbers and we are to predict which of them\n",
    "correspond to the target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12836f5",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfceb9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features(X) and target (y) variables\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99410b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06780019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d989b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eabe3557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2e0ac0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation on training data\n",
    "train_accuracy = model.score(X_train, y_train)\n",
    "print(\"Training Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15919f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's predict using our X_test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd4b43fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9694444444444444\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy manually\n",
    "train_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "907357a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       0.97      1.00      0.98        28\n",
      "           2       0.97      1.00      0.99        33\n",
      "           3       0.97      0.97      0.97        34\n",
      "           4       1.00      0.96      0.98        46\n",
      "           5       0.92      0.94      0.93        47\n",
      "           6       0.94      0.97      0.96        35\n",
      "           7       1.00      0.97      0.99        34\n",
      "           8       0.97      0.97      0.97        30\n",
      "           9       0.97      0.95      0.96        40\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c6d8a",
   "metadata": {},
   "source": [
    "### Results:\n",
    "The logistic regression model achieved an accuracy of 97% on the testing data, demonstrating its capability to accurately classify handwritten digits from the load_digits dataset. The classification report provided detailed insights into the model's precision, recall, and F1-score for each digit class, indicating satisfactory performance across all classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844cb785",
   "metadata": {},
   "source": [
    "### Saving the model\n",
    "Since the model is working perfectly, it's time to save it so that your team members can easily call it up to make predictions. To do this, we import the joblib library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e29afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8eefa996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image_class']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the model\n",
    "joblib.dump(model, 'image_class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4ec157",
   "metadata": {},
   "source": [
    "### What if we want to use the model?\n",
    "This can be done by loading the model on our notebook just like you would a dataset but this time, from the joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64f7be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and save it to a variable\n",
    "model_use = joblib.load('image_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aca6ed48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can then predict using this\n",
    "model_use.predict([X[8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e26dcf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more predictions\n",
    "model_use.predict(X[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7353d329",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "In conclusion, this project showcased the successful implementation of logistic regression for handwritten digit classification using the load_digits dataset. By leveraging fundamental machine learning concepts and thorough data analysis, I developed a reliable model capable of accurately predicting the digits represented in handwritten images. This project serves as a testament to my proficiency in image classification tasks and my ability to apply machine learning algorithms to real-world datasets.\n",
    "\n",
    "### Future Directions:\n",
    "Moving forward, I plan to explore advanced image classification techniques, such as convolutional neural networks (CNNs), to further enhance model performance. Additionally, I aim to deploy the model as a web application or integrate it into other projects for practical applications in optical character recognition (OCR) and digit recognition systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
